{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c94e9962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ca93f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>V</th>\n",
       "      <th>AP</th>\n",
       "      <th>RH</th>\n",
       "      <th>PE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.96</td>\n",
       "      <td>41.76</td>\n",
       "      <td>1024.07</td>\n",
       "      <td>73.17</td>\n",
       "      <td>463.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.18</td>\n",
       "      <td>62.96</td>\n",
       "      <td>1020.04</td>\n",
       "      <td>59.08</td>\n",
       "      <td>444.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.11</td>\n",
       "      <td>39.40</td>\n",
       "      <td>1012.16</td>\n",
       "      <td>92.14</td>\n",
       "      <td>488.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.86</td>\n",
       "      <td>57.32</td>\n",
       "      <td>1010.24</td>\n",
       "      <td>76.64</td>\n",
       "      <td>446.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.82</td>\n",
       "      <td>37.50</td>\n",
       "      <td>1009.23</td>\n",
       "      <td>96.62</td>\n",
       "      <td>473.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AT      V       AP     RH      PE\n",
       "0  14.96  41.76  1024.07  73.17  463.26\n",
       "1  25.18  62.96  1020.04  59.08  444.37\n",
       "2   5.11  39.40  1012.16  92.14  488.56\n",
       "3  20.86  57.32  1010.24  76.64  446.48\n",
       "4  10.82  37.50  1009.23  96.62  473.90"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"Folds5x2_pp.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4299d88e",
   "metadata": {},
   "source": [
    "* AT - Ambient Temperature\n",
    "* V - Exhaust Vacuum \n",
    "* AP - Ambient Pressure \n",
    "* RH - Relative Humidity\n",
    "* PE - energy output \n",
    "\n",
    "> We need to calculate how much energy output we are getting with the help of rest paremeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92d679c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  14.96,   41.76, 1024.07,   73.17],\n",
       "        [  25.18,   62.96, 1020.04,   59.08],\n",
       "        [   5.11,   39.4 , 1012.16,   92.14],\n",
       "        ...,\n",
       "        [  31.32,   74.33, 1012.92,   36.48],\n",
       "        [  24.48,   69.45, 1013.86,   62.39],\n",
       "        [  21.6 ,   62.52, 1017.23,   67.87]]),\n",
       " array([463.26, 444.37, 488.56, ..., 429.57, 435.74, 453.28]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad2eda2",
   "metadata": {},
   "source": [
    "As per the dataset there is no null value so we can directly split the data and train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23f8a7d",
   "metadata": {},
   "source": [
    "### Spliting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f454c88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f99a1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the shape of X and y\n",
    "X[0].ndim, y[0].ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed0f8f4",
   "metadata": {},
   "source": [
    "###  buliding the ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2364efaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Creating model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, input_shape = [4], name = \"Input_layer\"),\n",
    "    tf.keras.layers.Dense(1, input_shape = [1], name = \"output_layer\")\n",
    "], name = \"Model_1\")\n",
    "\n",
    "# Compiling model\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "              optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics = [\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cfce34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "240/240 [==============================] - 1s 908us/step - loss: 23.2196 - mae: 23.2196\n",
      "Epoch 2/100\n",
      "240/240 [==============================] - 0s 858us/step - loss: 5.4073 - mae: 5.4073\n",
      "Epoch 3/100\n",
      "240/240 [==============================] - 0s 887us/step - loss: 5.1529 - mae: 5.1529\n",
      "Epoch 4/100\n",
      "240/240 [==============================] - 0s 853us/step - loss: 4.6274 - mae: 4.6274\n",
      "Epoch 5/100\n",
      "240/240 [==============================] - 0s 841us/step - loss: 4.6139 - mae: 4.6139\n",
      "Epoch 6/100\n",
      "240/240 [==============================] - 0s 843us/step - loss: 4.4962 - mae: 4.4962\n",
      "Epoch 7/100\n",
      "240/240 [==============================] - 0s 845us/step - loss: 4.4525 - mae: 4.4525\n",
      "Epoch 8/100\n",
      "240/240 [==============================] - 0s 846us/step - loss: 4.4541 - mae: 4.4541\n",
      "Epoch 9/100\n",
      "240/240 [==============================] - 0s 845us/step - loss: 4.7092 - mae: 4.7092\n",
      "Epoch 10/100\n",
      "240/240 [==============================] - 0s 845us/step - loss: 4.9877 - mae: 4.9877\n",
      "Epoch 11/100\n",
      "240/240 [==============================] - 0s 845us/step - loss: 4.5856 - mae: 4.5856\n",
      "Epoch 12/100\n",
      "240/240 [==============================] - 0s 854us/step - loss: 4.4787 - mae: 4.4787\n",
      "Epoch 13/100\n",
      "240/240 [==============================] - 0s 845us/step - loss: 4.8349 - mae: 4.8349\n",
      "Epoch 14/100\n",
      "240/240 [==============================] - 0s 849us/step - loss: 4.4736 - mae: 4.4736\n",
      "Epoch 15/100\n",
      "240/240 [==============================] - 0s 845us/step - loss: 4.6297 - mae: 4.6297\n",
      "Epoch 16/100\n",
      "240/240 [==============================] - 0s 845us/step - loss: 4.5646 - mae: 4.5646\n",
      "Epoch 17/100\n",
      "240/240 [==============================] - 0s 854us/step - loss: 4.4927 - mae: 4.4927\n",
      "Epoch 18/100\n",
      "240/240 [==============================] - 0s 841us/step - loss: 4.4040 - mae: 4.4040\n",
      "Epoch 19/100\n",
      "240/240 [==============================] - 0s 858us/step - loss: 4.5284 - mae: 4.5284\n",
      "Epoch 20/100\n",
      "240/240 [==============================] - 0s 841us/step - loss: 4.5439 - mae: 4.5439\n",
      "Epoch 21/100\n",
      "240/240 [==============================] - 0s 858us/step - loss: 4.4405 - mae: 4.4405\n",
      "Epoch 22/100\n",
      "240/240 [==============================] - 0s 844us/step - loss: 4.5871 - mae: 4.5871\n",
      "Epoch 23/100\n",
      "240/240 [==============================] - 0s 841us/step - loss: 4.4416 - mae: 4.4416\n",
      "Epoch 24/100\n",
      "240/240 [==============================] - 0s 845us/step - loss: 4.4553 - mae: 4.4553\n",
      "Epoch 25/100\n",
      "240/240 [==============================] - 0s 844us/step - loss: 4.5930 - mae: 4.5930\n",
      "Epoch 26/100\n",
      "240/240 [==============================] - 0s 854us/step - loss: 4.5039 - mae: 4.5039\n",
      "Epoch 27/100\n",
      "240/240 [==============================] - 0s 878us/step - loss: 4.5471 - mae: 4.5471\n",
      "Epoch 28/100\n",
      "240/240 [==============================] - 0s 870us/step - loss: 4.5651 - mae: 4.5651\n",
      "Epoch 29/100\n",
      "240/240 [==============================] - 0s 858us/step - loss: 4.5201 - mae: 4.5201\n",
      "Epoch 30/100\n",
      "240/240 [==============================] - 0s 887us/step - loss: 4.6666 - mae: 4.6666\n",
      "Epoch 31/100\n",
      "240/240 [==============================] - 0s 883us/step - loss: 4.5769 - mae: 4.5769\n",
      "Epoch 32/100\n",
      "240/240 [==============================] - 0s 937us/step - loss: 4.4102 - mae: 4.4102\n",
      "Epoch 33/100\n",
      "240/240 [==============================] - 0s 858us/step - loss: 4.7031 - mae: 4.7031\n",
      "Epoch 34/100\n",
      "240/240 [==============================] - 0s 925us/step - loss: 4.4507 - mae: 4.4507\n",
      "Epoch 35/100\n",
      "240/240 [==============================] - 0s 858us/step - loss: 4.4088 - mae: 4.4088\n",
      "Epoch 36/100\n",
      "240/240 [==============================] - 0s 837us/step - loss: 4.5702 - mae: 4.5702\n",
      "Epoch 37/100\n",
      "240/240 [==============================] - 0s 887us/step - loss: 4.5029 - mae: 4.5029\n",
      "Epoch 38/100\n",
      "240/240 [==============================] - 0s 854us/step - loss: 4.5933 - mae: 4.5933\n",
      "Epoch 39/100\n",
      "240/240 [==============================] - 0s 879us/step - loss: 4.5226 - mae: 4.5226\n",
      "Epoch 40/100\n",
      "240/240 [==============================] - 0s 879us/step - loss: 4.5718 - mae: 4.5718\n",
      "Epoch 41/100\n",
      "240/240 [==============================] - 0s 849us/step - loss: 4.4682 - mae: 4.4682\n",
      "Epoch 42/100\n",
      "240/240 [==============================] - 0s 833us/step - loss: 4.3457 - mae: 4.3457\n",
      "Epoch 43/100\n",
      "240/240 [==============================] - 0s 870us/step - loss: 4.5519 - mae: 4.5519\n",
      "Epoch 44/100\n",
      "240/240 [==============================] - 0s 855us/step - loss: 4.3777 - mae: 4.3777\n",
      "Epoch 45/100\n",
      "240/240 [==============================] - 0s 837us/step - loss: 4.5579 - mae: 4.5579\n",
      "Epoch 46/100\n",
      "240/240 [==============================] - 0s 866us/step - loss: 4.3060 - mae: 4.3060\n",
      "Epoch 47/100\n",
      "240/240 [==============================] - 0s 849us/step - loss: 4.5039 - mae: 4.5039\n",
      "Epoch 48/100\n",
      "240/240 [==============================] - 0s 858us/step - loss: 4.8409 - mae: 4.8409\n",
      "Epoch 49/100\n",
      "240/240 [==============================] - 0s 828us/step - loss: 4.4507 - mae: 4.4507\n",
      "Epoch 50/100\n",
      "240/240 [==============================] - 0s 845us/step - loss: 4.4473 - mae: 4.4473\n",
      "Epoch 51/100\n",
      "240/240 [==============================] - 0s 854us/step - loss: 4.6986 - mae: 4.6986\n",
      "Epoch 52/100\n",
      "240/240 [==============================] - 0s 862us/step - loss: 4.4182 - mae: 4.4182\n",
      "Epoch 53/100\n",
      "240/240 [==============================] - 0s 870us/step - loss: 4.6059 - mae: 4.6059\n",
      "Epoch 54/100\n",
      "240/240 [==============================] - 0s 870us/step - loss: 4.4174 - mae: 4.4174\n",
      "Epoch 55/100\n",
      "240/240 [==============================] - 0s 845us/step - loss: 4.6087 - mae: 4.6087\n",
      "Epoch 56/100\n",
      "240/240 [==============================] - 0s 831us/step - loss: 4.5054 - mae: 4.5054\n",
      "Epoch 57/100\n",
      "240/240 [==============================] - 0s 834us/step - loss: 4.5684 - mae: 4.5684\n",
      "Epoch 58/100\n",
      "240/240 [==============================] - 0s 833us/step - loss: 4.3614 - mae: 4.3614\n",
      "Epoch 59/100\n",
      "240/240 [==============================] - 0s 904us/step - loss: 4.4442 - mae: 4.4442\n",
      "Epoch 60/100\n",
      "240/240 [==============================] - 0s 866us/step - loss: 4.5077 - mae: 4.5077\n",
      "Epoch 61/100\n",
      "240/240 [==============================] - 0s 941us/step - loss: 4.5106 - mae: 4.5106\n",
      "Epoch 62/100\n",
      "240/240 [==============================] - 0s 891us/step - loss: 4.5714 - mae: 4.5714\n",
      "Epoch 63/100\n",
      "240/240 [==============================] - 0s 910us/step - loss: 4.5274 - mae: 4.5274\n",
      "Epoch 64/100\n",
      "240/240 [==============================] - 0s 912us/step - loss: 4.3349 - mae: 4.3349\n",
      "Epoch 65/100\n",
      "240/240 [==============================] - 0s 896us/step - loss: 4.6366 - mae: 4.6366\n",
      "Epoch 66/100\n",
      "240/240 [==============================] - 0s 870us/step - loss: 4.2995 - mae: 4.2995\n",
      "Epoch 67/100\n",
      "240/240 [==============================] - 0s 872us/step - loss: 4.4315 - mae: 4.4315\n",
      "Epoch 68/100\n",
      "240/240 [==============================] - 0s 841us/step - loss: 4.4828 - mae: 4.4828\n",
      "Epoch 69/100\n",
      "240/240 [==============================] - 0s 868us/step - loss: 4.6190 - mae: 4.6190\n",
      "Epoch 70/100\n",
      "240/240 [==============================] - 0s 849us/step - loss: 4.4572 - mae: 4.4572\n",
      "Epoch 71/100\n",
      "240/240 [==============================] - 0s 858us/step - loss: 4.6729 - mae: 4.6729\n",
      "Epoch 72/100\n",
      "240/240 [==============================] - 0s 883us/step - loss: 4.3795 - mae: 4.3795\n",
      "Epoch 73/100\n",
      "240/240 [==============================] - 0s 887us/step - loss: 4.4596 - mae: 4.4596\n",
      "Epoch 74/100\n",
      "240/240 [==============================] - 0s 962us/step - loss: 4.5106 - mae: 4.5106\n",
      "Epoch 75/100\n",
      "240/240 [==============================] - 0s 891us/step - loss: 4.3964 - mae: 4.3964\n",
      "Epoch 76/100\n",
      "240/240 [==============================] - 0s 858us/step - loss: 4.4634 - mae: 4.4634\n",
      "Epoch 77/100\n",
      "240/240 [==============================] - 0s 866us/step - loss: 4.4872 - mae: 4.4872\n",
      "Epoch 78/100\n",
      "240/240 [==============================] - 0s 879us/step - loss: 4.4111 - mae: 4.4111\n",
      "Epoch 79/100\n",
      "240/240 [==============================] - 0s 862us/step - loss: 4.3870 - mae: 4.3870\n",
      "Epoch 80/100\n",
      "240/240 [==============================] - 0s 841us/step - loss: 4.4569 - mae: 4.4569\n",
      "Epoch 81/100\n",
      "240/240 [==============================] - 0s 845us/step - loss: 4.2862 - mae: 4.2862\n",
      "Epoch 82/100\n",
      "240/240 [==============================] - 0s 854us/step - loss: 4.4289 - mae: 4.4289\n",
      "Epoch 83/100\n",
      "240/240 [==============================] - 0s 866us/step - loss: 4.4532 - mae: 4.4532\n",
      "Epoch 84/100\n",
      "240/240 [==============================] - 0s 862us/step - loss: 4.4967 - mae: 4.4967\n",
      "Epoch 85/100\n",
      "240/240 [==============================] - 0s 864us/step - loss: 4.3799 - mae: 4.3799\n",
      "Epoch 86/100\n",
      "240/240 [==============================] - 0s 838us/step - loss: 4.6667 - mae: 4.6667\n",
      "Epoch 87/100\n",
      "240/240 [==============================] - 0s 841us/step - loss: 4.4644 - mae: 4.4644\n",
      "Epoch 88/100\n",
      "240/240 [==============================] - 0s 868us/step - loss: 4.3997 - mae: 4.3997\n",
      "Epoch 89/100\n",
      "240/240 [==============================] - 0s 849us/step - loss: 4.5206 - mae: 4.5206\n",
      "Epoch 90/100\n",
      "240/240 [==============================] - 0s 849us/step - loss: 4.4988 - mae: 4.4988\n",
      "Epoch 91/100\n",
      "240/240 [==============================] - 0s 858us/step - loss: 4.4134 - mae: 4.4134\n",
      "Epoch 92/100\n",
      "240/240 [==============================] - 0s 841us/step - loss: 4.5045 - mae: 4.5045\n",
      "Epoch 93/100\n",
      "240/240 [==============================] - 0s 862us/step - loss: 4.3458 - mae: 4.3458\n",
      "Epoch 94/100\n",
      "240/240 [==============================] - 0s 845us/step - loss: 4.6706 - mae: 4.6706\n",
      "Epoch 95/100\n",
      "240/240 [==============================] - 0s 841us/step - loss: 4.3543 - mae: 4.3543\n",
      "Epoch 96/100\n",
      "240/240 [==============================] - 0s 870us/step - loss: 4.5073 - mae: 4.5073\n",
      "Epoch 97/100\n",
      "240/240 [==============================] - 0s 866us/step - loss: 4.7808 - mae: 4.7808\n",
      "Epoch 98/100\n",
      "240/240 [==============================] - 0s 854us/step - loss: 4.4951 - mae: 4.4951\n",
      "Epoch 99/100\n",
      "240/240 [==============================] - 0s 841us/step - loss: 4.4515 - mae: 4.4515\n",
      "Epoch 100/100\n",
      "240/240 [==============================] - 0s 862us/step - loss: 4.5435 - mae: 4.5435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x19c6c816b20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f5768ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (Dense)         (None, 100)               500       \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 601 (2.35 KB)\n",
      "Trainable params: 601 (2.35 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Shows the layers (Model 1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9139a2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 820us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[454.18445],\n",
       "       [436.13025],\n",
       "       [430.90482],\n",
       "       ...,\n",
       "       [478.87173],\n",
       "       [432.94775],\n",
       "       [457.04428]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c84f704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.ndim, y_pred.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee9df2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(y_test, y_pred):\n",
    "    mae = tf.metrics.mean_absolute_error(y_true = y_test, \n",
    "                                         y_pred = tf.squeeze(y_pred)) # Squeeze to remove extra dimension\n",
    "    mse = tf.metrics.mean_squared_error(y_true = y_test, \n",
    "                                         y_pred = tf.squeeze(y_pred))\n",
    "    \n",
    "    return mae, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "781816b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (Dense)         (None, 100)               500       \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 601 (2.35 KB)\n",
      "Trainable params: 601 (2.35 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Shows the layers (model 2 changin lr 0.001 -> 0.01)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50206a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 763us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[456.03693],\n",
       "       [437.6327 ],\n",
       "       [432.42734],\n",
       "       ...,\n",
       "       [481.00665],\n",
       "       [434.47922],\n",
       "       [458.75232]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions (model 2 changin lr 0.001 -> 0.01)\n",
    "y_pred_2 = model.predict(X_test)\n",
    "y_pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58d3a2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (Dense)         (None, 100)               500       \n",
      "                                                                 \n",
      " Input_layer_2 (Dense)       (None, 100)               10100     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10701 (41.80 KB)\n",
      "Trainable params: 10701 (41.80 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Shows the layers (model 3 changing adding another layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b7e047e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 830us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[460.5734 ],\n",
       "       [442.086  ],\n",
       "       [436.9484 ],\n",
       "       ...,\n",
       "       [485.4536 ],\n",
       "       [438.99844],\n",
       "       [463.1504 ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions (model 3 changing adding another layer)\n",
    "y_pred_3 = model.predict(X_test)\n",
    "y_pred_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "547d0011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=4.3962727>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=31.275087>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_v1, mse_v1 = evaluation(y_test, y_pred)\n",
    "mae_v2, mse_v2 = evaluation(y_test, y_pred_2)\n",
    "mae_v3, mse_v3 = evaluation(y_test, y_pred_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f1840d",
   "metadata": {},
   "source": [
    "### Comparing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff1357e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model_1</td>\n",
       "      <td>4.396273</td>\n",
       "      <td>31.275087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model_2</td>\n",
       "      <td>3.989280</td>\n",
       "      <td>25.602091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model_3</td>\n",
       "      <td>5.119936</td>\n",
       "      <td>39.160980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model       MAE        MSE\n",
       "0  Model_1  4.396273  31.275087\n",
       "1  Model_2  3.989280  25.602091\n",
       "2  Model_3  5.119936  39.160980"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results = [[\"Model_1\", mae_v1.numpy(), mse_v1.numpy()],\n",
    "                [\"Model_2\", mae_v2.numpy(), mse_v2.numpy()],\n",
    "                [\"Model_3\", mae_v3.numpy(), mse_v3.numpy()]]\n",
    "\n",
    "all_results = pd.DataFrame(model_results, columns=[\"Model\", \"MAE\", \"MSE\"])\n",
    "all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c731d2f",
   "metadata": {},
   "source": [
    "## Optimizing the Model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98f26dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model 2 changing lr 0.001 -> 0.01\n",
    "\n",
    "# buliding the ANN Model\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Creating model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, input_shape = [4], name = \"Input_layer\"),\n",
    "    tf.keras.layers.Dense(100, input_shape = [4], name = \"Input_layer_2\"),\n",
    "    tf.keras.layers.Dense(100, input_shape = [4], name = \"Input_layer_3\"),\n",
    "    tf.keras.layers.Dense(1, input_shape = [1], name = \"output_layer\")\n",
    "], name = \"Model_2\")\n",
    "\n",
    "# Compiling model\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "              optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "              metrics = [\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b035825",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "240/240 [==============================] - 2s 1ms/step - loss: 89.9663 - mae: 89.9663\n",
      "Epoch 2/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 18.6098 - mae: 18.6098\n",
      "Epoch 3/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 14.1799 - mae: 14.1799\n",
      "Epoch 4/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 9.3825 - mae: 9.3825\n",
      "Epoch 5/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 7.9406 - mae: 7.9406\n",
      "Epoch 6/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 8.4930 - mae: 8.4930\n",
      "Epoch 7/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 8.0538 - mae: 8.0538\n",
      "Epoch 8/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 7.3937 - mae: 7.3937\n",
      "Epoch 9/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 6.8013 - mae: 6.8013\n",
      "Epoch 10/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 7.5129 - mae: 7.5129\n",
      "Epoch 11/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 8.1955 - mae: 8.1955\n",
      "Epoch 12/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 6.6385 - mae: 6.6385\n",
      "Epoch 13/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 7.5008 - mae: 7.5008\n",
      "Epoch 14/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 6.6106 - mae: 6.6106\n",
      "Epoch 15/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 9.5080 - mae: 9.5080\n",
      "Epoch 16/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 7.2308 - mae: 7.2308\n",
      "Epoch 17/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 6.3030 - mae: 6.3030\n",
      "Epoch 18/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 6.6797 - mae: 6.6797\n",
      "Epoch 19/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 41.4077 - mae: 41.4077\n",
      "Epoch 20/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 6.2878 - mae: 6.2878\n",
      "Epoch 21/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.8528 - mae: 5.8528\n",
      "Epoch 22/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.5152 - mae: 5.5152\n",
      "Epoch 23/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 7.3596 - mae: 7.3596\n",
      "Epoch 24/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.6355 - mae: 5.6355\n",
      "Epoch 25/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.8305 - mae: 5.8305\n",
      "Epoch 26/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.7733 - mae: 5.7733\n",
      "Epoch 27/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.8041 - mae: 5.8041\n",
      "Epoch 28/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 7.8232 - mae: 7.8232\n",
      "Epoch 29/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.8581 - mae: 5.8581\n",
      "Epoch 30/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.8079 - mae: 5.8079\n",
      "Epoch 31/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 6.1069 - mae: 6.1069\n",
      "Epoch 32/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.7911 - mae: 5.7911\n",
      "Epoch 33/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 15.7972 - mae: 15.7972\n",
      "Epoch 34/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 12.4387 - mae: 12.4387\n",
      "Epoch 35/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.3200 - mae: 5.3200\n",
      "Epoch 36/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.1078 - mae: 5.1078\n",
      "Epoch 37/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.1116 - mae: 5.1116\n",
      "Epoch 38/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 6.2395 - mae: 6.2395\n",
      "Epoch 39/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.8578 - mae: 5.8578\n",
      "Epoch 40/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.4139 - mae: 5.4139\n",
      "Epoch 41/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9931 - mae: 4.9931\n",
      "Epoch 42/500\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 5.3504 - mae: 5.3504\n",
      "Epoch 43/500\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 111.0172 - mae: 111.0172\n",
      "Epoch 44/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 22.2232 - mae: 22.2232\n",
      "Epoch 45/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 6.1841 - mae: 6.1841\n",
      "Epoch 46/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 6.4508 - mae: 6.4508\n",
      "Epoch 47/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.7255 - mae: 5.7255\n",
      "Epoch 48/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 6.2290 - mae: 6.2290\n",
      "Epoch 49/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.1130 - mae: 5.1130\n",
      "Epoch 50/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.8196 - mae: 5.8196\n",
      "Epoch 51/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.1908 - mae: 5.1908\n",
      "Epoch 52/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.3532 - mae: 5.3532\n",
      "Epoch 53/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.3071 - mae: 5.3071\n",
      "Epoch 54/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.4744 - mae: 5.4744\n",
      "Epoch 55/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.2786 - mae: 5.2786\n",
      "Epoch 56/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.1305 - mae: 5.1305\n",
      "Epoch 57/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.2033 - mae: 5.2033\n",
      "Epoch 58/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.9839 - mae: 5.9839\n",
      "Epoch 59/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.1967 - mae: 5.1967\n",
      "Epoch 60/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.3170 - mae: 5.3170\n",
      "Epoch 61/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.0520 - mae: 5.0520\n",
      "Epoch 62/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 56.8377 - mae: 56.8377\n",
      "Epoch 63/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.7565 - mae: 5.7565\n",
      "Epoch 64/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.5044 - mae: 5.5044\n",
      "Epoch 65/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.4116 - mae: 5.4116\n",
      "Epoch 66/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.2772 - mae: 5.2772\n",
      "Epoch 67/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.1101 - mae: 5.1101\n",
      "Epoch 68/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.5840 - mae: 5.5840\n",
      "Epoch 69/500\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 4.9559 - mae: 4.9559\n",
      "Epoch 70/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 6.2124 - mae: 6.2124\n",
      "Epoch 71/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 7.4705 - mae: 7.4705\n",
      "Epoch 72/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.0871 - mae: 5.0871\n",
      "Epoch 73/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.2524 - mae: 5.2524\n",
      "Epoch 74/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9907 - mae: 4.9907\n",
      "Epoch 75/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.4157 - mae: 5.4157\n",
      "Epoch 76/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.5822 - mae: 5.5822\n",
      "Epoch 77/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 36.4320 - mae: 36.4320\n",
      "Epoch 78/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9633 - mae: 4.9633\n",
      "Epoch 79/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.1264 - mae: 5.1264\n",
      "Epoch 80/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8802 - mae: 4.8802\n",
      "Epoch 81/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.3621 - mae: 5.3621\n",
      "Epoch 82/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.5400 - mae: 5.5400\n",
      "Epoch 83/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.2505 - mae: 5.2505\n",
      "Epoch 84/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.0228 - mae: 5.0228\n",
      "Epoch 85/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7791 - mae: 4.7791\n",
      "Epoch 86/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.1566 - mae: 5.1566\n",
      "Epoch 87/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8237 - mae: 4.8237\n",
      "Epoch 88/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.6760 - mae: 5.6760\n",
      "Epoch 89/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.1757 - mae: 5.1757\n",
      "Epoch 90/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9108 - mae: 4.9108\n",
      "Epoch 91/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 22.5058 - mae: 22.5058\n",
      "Epoch 92/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.1634 - mae: 5.1634\n",
      "Epoch 93/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.3384 - mae: 5.3384\n",
      "Epoch 94/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.3672 - mae: 5.3672\n",
      "Epoch 95/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6759 - mae: 4.6759\n",
      "Epoch 96/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6731 - mae: 4.6731\n",
      "Epoch 97/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8426 - mae: 4.8426\n",
      "Epoch 98/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8141 - mae: 4.8141\n",
      "Epoch 99/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5868 - mae: 4.5868\n",
      "Epoch 100/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6239 - mae: 4.6239\n",
      "Epoch 101/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8899 - mae: 4.8899\n",
      "Epoch 102/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.6861 - mae: 5.6861\n",
      "Epoch 103/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 18.6000 - mae: 18.6000\n",
      "Epoch 104/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.0746 - mae: 5.0746\n",
      "Epoch 105/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7153 - mae: 4.7153\n",
      "Epoch 106/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.3237 - mae: 5.3237\n",
      "Epoch 107/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9579 - mae: 4.9579\n",
      "Epoch 108/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.2125 - mae: 5.2125\n",
      "Epoch 109/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7709 - mae: 4.7709\n",
      "Epoch 110/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.0725 - mae: 5.0725\n",
      "Epoch 111/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9165 - mae: 4.9165\n",
      "Epoch 112/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 108.5344 - mae: 108.5344\n",
      "Epoch 113/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.5917 - mae: 5.5917\n",
      "Epoch 114/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.0563 - mae: 5.0563\n",
      "Epoch 115/500\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 5.0065 - mae: 5.0065\n",
      "Epoch 116/500\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 5.3174 - mae: 5.3174\n",
      "Epoch 117/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8650 - mae: 4.8650\n",
      "Epoch 118/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8749 - mae: 4.8749\n",
      "Epoch 119/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6923 - mae: 4.6923\n",
      "Epoch 120/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8929 - mae: 4.8929\n",
      "Epoch 121/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7388 - mae: 4.7388\n",
      "Epoch 122/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.1435 - mae: 5.1435\n",
      "Epoch 123/500\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 4.9493 - mae: 4.9493\n",
      "Epoch 124/500\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 4.8726 - mae: 4.8726\n",
      "Epoch 125/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9171 - mae: 4.9171\n",
      "Epoch 126/500\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 4.6307 - mae: 4.6307\n",
      "Epoch 127/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.6472 - mae: 5.6472\n",
      "Epoch 128/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.0377 - mae: 5.0377\n",
      "Epoch 129/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7103 - mae: 4.7103\n",
      "Epoch 130/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8251 - mae: 4.8251\n",
      "Epoch 131/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5936 - mae: 4.5936\n",
      "Epoch 132/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7775 - mae: 4.7775\n",
      "Epoch 133/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.6119 - mae: 5.6119\n",
      "Epoch 134/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9297 - mae: 4.9297\n",
      "Epoch 135/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9179 - mae: 4.9179\n",
      "Epoch 136/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6612 - mae: 4.6612\n",
      "Epoch 137/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 6.7115 - mae: 6.7115\n",
      "Epoch 138/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.8984 - mae: 5.8984\n",
      "Epoch 139/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8235 - mae: 4.8235\n",
      "Epoch 140/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7763 - mae: 4.7763\n",
      "Epoch 141/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 6.5861 - mae: 6.5861\n",
      "Epoch 142/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8153 - mae: 4.8153\n",
      "Epoch 143/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 22.2639 - mae: 22.2639\n",
      "Epoch 144/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.8530 - mae: 5.8530\n",
      "Epoch 145/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6408 - mae: 4.6408\n",
      "Epoch 146/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7816 - mae: 4.7816\n",
      "Epoch 147/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7786 - mae: 4.7786\n",
      "Epoch 148/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5133 - mae: 4.5133\n",
      "Epoch 149/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5628 - mae: 4.5628\n",
      "Epoch 150/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5323 - mae: 4.5323\n",
      "Epoch 151/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8879 - mae: 4.8879\n",
      "Epoch 152/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8887 - mae: 4.8887\n",
      "Epoch 153/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5869 - mae: 4.5869\n",
      "Epoch 154/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.4724 - mae: 4.4724\n",
      "Epoch 155/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 9.3319 - mae: 9.3319\n",
      "Epoch 156/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 19.0226 - mae: 19.0226\n",
      "Epoch 157/500\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 4.8735 - mae: 4.8735\n",
      "Epoch 158/500\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 4.4016 - mae: 4.4016\n",
      "Epoch 159/500\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 4.7803 - mae: 4.7803\n",
      "Epoch 160/500\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 4.7183 - mae: 4.7183\n",
      "Epoch 161/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7516 - mae: 4.7516\n",
      "Epoch 162/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5531 - mae: 4.5531\n",
      "Epoch 163/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 0s 2ms/step - loss: 5.1806 - mae: 5.1806\n",
      "Epoch 164/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7856 - mae: 4.7856\n",
      "Epoch 165/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7152 - mae: 4.7152\n",
      "Epoch 166/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7187 - mae: 4.7187\n",
      "Epoch 167/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5753 - mae: 4.5753\n",
      "Epoch 168/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6346 - mae: 4.6346\n",
      "Epoch 169/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 62.9722 - mae: 62.9722\n",
      "Epoch 170/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 155.9220 - mae: 155.9220\n",
      "Epoch 171/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.1405 - mae: 5.1405\n",
      "Epoch 172/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8260 - mae: 4.8260\n",
      "Epoch 173/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7986 - mae: 4.7986\n",
      "Epoch 174/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.1438 - mae: 5.1438\n",
      "Epoch 175/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.5113 - mae: 5.5113\n",
      "Epoch 176/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.4202 - mae: 5.4202\n",
      "Epoch 177/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8148 - mae: 4.8148\n",
      "Epoch 178/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7876 - mae: 4.7876\n",
      "Epoch 179/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7166 - mae: 4.7166\n",
      "Epoch 180/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6081 - mae: 4.6081\n",
      "Epoch 181/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8201 - mae: 4.8201\n",
      "Epoch 182/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.2099 - mae: 5.2099\n",
      "Epoch 183/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9720 - mae: 4.9720\n",
      "Epoch 184/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7434 - mae: 4.7434\n",
      "Epoch 185/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7362 - mae: 4.7362\n",
      "Epoch 186/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9237 - mae: 4.9237\n",
      "Epoch 187/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7735 - mae: 4.7735\n",
      "Epoch 188/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7895 - mae: 4.7895\n",
      "Epoch 189/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8251 - mae: 4.8251\n",
      "Epoch 190/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.2303 - mae: 5.2303\n",
      "Epoch 191/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5858 - mae: 4.5858\n",
      "Epoch 192/500\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 4.5064 - mae: 4.5064\n",
      "Epoch 193/500\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 4.6286 - mae: 4.6286\n",
      "Epoch 194/500\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 4.7067 - mae: 4.7067\n",
      "Epoch 195/500\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 5.0470 - mae: 5.0470\n",
      "Epoch 196/500\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 5.0485 - mae: 5.0485\n",
      "Epoch 197/500\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 4.6733 - mae: 4.6733\n",
      "Epoch 198/500\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 4.8586 - mae: 4.8586\n",
      "Epoch 199/500\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 4.6998 - mae: 4.6998\n",
      "Epoch 200/500\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 38.9321 - mae: 38.9321\n",
      "Epoch 201/500\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 4.6000 - mae: 4.6000\n",
      "Epoch 202/500\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 4.6512 - mae: 4.6512\n",
      "Epoch 203/500\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 4.6122 - mae: 4.6122\n",
      "Epoch 204/500\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 4.8828 - mae: 4.8828\n",
      "Epoch 205/500\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 4.7895 - mae: 4.7895\n",
      "Epoch 206/500\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 4.9265 - mae: 4.9265\n",
      "Epoch 207/500\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 4.5512 - mae: 4.5512\n",
      "Epoch 208/500\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 4.8995 - mae: 4.8995\n",
      "Epoch 209/500\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 4.5750 - mae: 4.5750\n",
      "Epoch 210/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5113 - mae: 4.5113\n",
      "Epoch 211/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.1453 - mae: 5.1453\n",
      "Epoch 212/500\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 4.9350 - mae: 4.9350\n",
      "Epoch 213/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7319 - mae: 4.7319\n",
      "Epoch 214/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6734 - mae: 4.6734\n",
      "Epoch 215/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.4624 - mae: 5.4624\n",
      "Epoch 216/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8314 - mae: 4.8314\n",
      "Epoch 217/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6812 - mae: 4.6812\n",
      "Epoch 218/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.4957 - mae: 4.4957\n",
      "Epoch 219/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6674 - mae: 4.6674\n",
      "Epoch 220/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9106 - mae: 4.9106\n",
      "Epoch 221/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.0469 - mae: 5.0469\n",
      "Epoch 222/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7543 - mae: 4.7543\n",
      "Epoch 223/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7051 - mae: 4.7051\n",
      "Epoch 224/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.4980 - mae: 5.4980\n",
      "Epoch 225/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6914 - mae: 4.6914\n",
      "Epoch 226/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9114 - mae: 4.9114\n",
      "Epoch 227/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5386 - mae: 4.5386\n",
      "Epoch 228/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7173 - mae: 4.7173\n",
      "Epoch 229/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 116.3819 - mae: 116.3819\n",
      "Epoch 230/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 6.0425 - mae: 6.0425\n",
      "Epoch 231/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.1537 - mae: 5.1537\n",
      "Epoch 232/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8416 - mae: 4.8416\n",
      "Epoch 233/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.2271 - mae: 5.2271\n",
      "Epoch 234/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.0267 - mae: 5.0267\n",
      "Epoch 235/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7457 - mae: 4.7457\n",
      "Epoch 236/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.1604 - mae: 5.1604\n",
      "Epoch 237/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.2421 - mae: 5.2421\n",
      "Epoch 238/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7934 - mae: 4.7934\n",
      "Epoch 239/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7895 - mae: 4.7895\n",
      "Epoch 240/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9836 - mae: 4.9836\n",
      "Epoch 241/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8613 - mae: 4.8613\n",
      "Epoch 242/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6886 - mae: 4.6886\n",
      "Epoch 243/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5827 - mae: 4.5827\n",
      "Epoch 244/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8211 - mae: 4.8211\n",
      "Epoch 245/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.1572 - mae: 5.1572\n",
      "Epoch 246/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6678 - mae: 4.6678\n",
      "Epoch 247/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.0670 - mae: 5.0670\n",
      "Epoch 248/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8552 - mae: 4.8552\n",
      "Epoch 249/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7853 - mae: 4.7853\n",
      "Epoch 250/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 6.0700 - mae: 6.0700\n",
      "Epoch 251/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8605 - mae: 4.8605\n",
      "Epoch 252/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5905 - mae: 4.5905\n",
      "Epoch 253/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7519 - mae: 4.7519\n",
      "Epoch 254/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 7.5747 - mae: 7.5747\n",
      "Epoch 255/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7511 - mae: 4.7511\n",
      "Epoch 256/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5522 - mae: 4.5522\n",
      "Epoch 257/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8646 - mae: 4.8646\n",
      "Epoch 258/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5680 - mae: 4.5680\n",
      "Epoch 259/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.3020 - mae: 5.3020\n",
      "Epoch 260/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 19.7672 - mae: 19.7672\n",
      "Epoch 261/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7322 - mae: 4.7322\n",
      "Epoch 262/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6044 - mae: 4.6044\n",
      "Epoch 263/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.4227 - mae: 4.4227\n",
      "Epoch 264/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6197 - mae: 4.6197\n",
      "Epoch 265/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6756 - mae: 4.6756\n",
      "Epoch 266/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6035 - mae: 4.6035\n",
      "Epoch 267/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.4366 - mae: 4.4366\n",
      "Epoch 268/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8022 - mae: 4.8022\n",
      "Epoch 269/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6169 - mae: 4.6169\n",
      "Epoch 270/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5420 - mae: 4.5420\n",
      "Epoch 271/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.0404 - mae: 5.0404\n",
      "Epoch 272/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7289 - mae: 4.7289\n",
      "Epoch 273/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5894 - mae: 4.5894\n",
      "Epoch 274/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7063 - mae: 4.7063\n",
      "Epoch 275/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8309 - mae: 4.8309\n",
      "Epoch 276/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7434 - mae: 4.7434\n",
      "Epoch 277/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7263 - mae: 4.7263\n",
      "Epoch 278/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6781 - mae: 4.6781\n",
      "Epoch 279/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9688 - mae: 4.9688\n",
      "Epoch 280/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 109.1632 - mae: 109.1632\n",
      "Epoch 281/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7550 - mae: 4.7550\n",
      "Epoch 282/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7651 - mae: 4.7651\n",
      "Epoch 283/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6530 - mae: 4.6530\n",
      "Epoch 284/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9832 - mae: 4.9832\n",
      "Epoch 285/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6269 - mae: 4.6269\n",
      "Epoch 286/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6553 - mae: 4.6553\n",
      "Epoch 287/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7062 - mae: 4.7062\n",
      "Epoch 288/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8314 - mae: 4.8314\n",
      "Epoch 289/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.4414 - mae: 4.4414\n",
      "Epoch 290/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.0874 - mae: 5.0874\n",
      "Epoch 291/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6176 - mae: 4.6176\n",
      "Epoch 292/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6583 - mae: 4.6583\n",
      "Epoch 293/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5045 - mae: 4.5045\n",
      "Epoch 294/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7328 - mae: 4.7328\n",
      "Epoch 295/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9701 - mae: 4.9701\n",
      "Epoch 296/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6188 - mae: 4.6188\n",
      "Epoch 297/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6384 - mae: 4.6384\n",
      "Epoch 298/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5874 - mae: 4.5874\n",
      "Epoch 299/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7984 - mae: 4.7984\n",
      "Epoch 300/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 7.0461 - mae: 7.0461\n",
      "Epoch 301/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5763 - mae: 4.5763\n",
      "Epoch 302/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6866 - mae: 4.6866\n",
      "Epoch 303/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6488 - mae: 4.6488\n",
      "Epoch 304/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8918 - mae: 4.8918\n",
      "Epoch 305/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5000 - mae: 4.5000\n",
      "Epoch 306/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5482 - mae: 4.5482\n",
      "Epoch 307/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8790 - mae: 4.8790\n",
      "Epoch 308/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5879 - mae: 4.5879\n",
      "Epoch 309/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8997 - mae: 4.8997\n",
      "Epoch 310/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8733 - mae: 4.8733\n",
      "Epoch 311/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.4405 - mae: 5.4405\n",
      "Epoch 312/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7095 - mae: 4.7095\n",
      "Epoch 313/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5579 - mae: 4.5579\n",
      "Epoch 314/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5434 - mae: 4.5434\n",
      "Epoch 315/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6735 - mae: 4.6735\n",
      "Epoch 316/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6760 - mae: 4.6760\n",
      "Epoch 317/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 107.8450 - mae: 107.8450\n",
      "Epoch 318/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 58.3621 - mae: 58.3621\n",
      "Epoch 319/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.0876 - mae: 5.0876\n",
      "Epoch 320/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.0070 - mae: 5.0070\n",
      "Epoch 321/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.3420 - mae: 5.3420\n",
      "Epoch 322/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8312 - mae: 4.8312\n",
      "Epoch 323/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.3286 - mae: 5.3286\n",
      "Epoch 324/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.1051 - mae: 5.1051\n",
      "Epoch 325/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7628 - mae: 4.7628\n",
      "Epoch 326/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.2281 - mae: 5.2281\n",
      "Epoch 327/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.0769 - mae: 5.0769\n",
      "Epoch 328/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.0261 - mae: 5.0261\n",
      "Epoch 329/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9080 - mae: 4.9080\n",
      "Epoch 330/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6020 - mae: 4.6020\n",
      "Epoch 331/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7347 - mae: 4.7347\n",
      "Epoch 332/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5769 - mae: 4.5769\n",
      "Epoch 333/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5626 - mae: 4.5626\n",
      "Epoch 334/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7585 - mae: 4.7585\n",
      "Epoch 335/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6715 - mae: 4.6715\n",
      "Epoch 336/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.4856 - mae: 4.4856\n",
      "Epoch 337/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7190 - mae: 4.7190\n",
      "Epoch 338/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6492 - mae: 4.6492\n",
      "Epoch 339/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.2732 - mae: 5.2732\n",
      "Epoch 340/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 39.0233 - mae: 39.0233\n",
      "Epoch 341/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.3885 - mae: 4.3885\n",
      "Epoch 342/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7122 - mae: 4.7122\n",
      "Epoch 343/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7359 - mae: 4.7359\n",
      "Epoch 344/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.4363 - mae: 4.4363\n",
      "Epoch 345/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7041 - mae: 4.7041\n",
      "Epoch 346/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6267 - mae: 4.6267\n",
      "Epoch 347/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5139 - mae: 4.5139\n",
      "Epoch 348/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5914 - mae: 4.5914\n",
      "Epoch 349/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5749 - mae: 4.5749\n",
      "Epoch 350/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7068 - mae: 4.7068\n",
      "Epoch 351/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.3843 - mae: 4.3843\n",
      "Epoch 352/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5574 - mae: 4.5574\n",
      "Epoch 353/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5986 - mae: 4.5986\n",
      "Epoch 354/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6761 - mae: 4.6761\n",
      "Epoch 355/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6449 - mae: 4.6449\n",
      "Epoch 356/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7156 - mae: 4.7156\n",
      "Epoch 357/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6575 - mae: 4.6575\n",
      "Epoch 358/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.4128 - mae: 5.4128\n",
      "Epoch 359/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5751 - mae: 4.5751\n",
      "Epoch 360/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.0596 - mae: 5.0596\n",
      "Epoch 361/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 15.3558 - mae: 15.3558\n",
      "Epoch 362/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7804 - mae: 4.7804\n",
      "Epoch 363/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.4499 - mae: 4.4499\n",
      "Epoch 364/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6259 - mae: 4.6259\n",
      "Epoch 365/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5705 - mae: 4.5705\n",
      "Epoch 366/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5827 - mae: 4.5827\n",
      "Epoch 367/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7068 - mae: 4.7068\n",
      "Epoch 368/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5120 - mae: 4.5120\n",
      "Epoch 369/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6063 - mae: 4.6063\n",
      "Epoch 370/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6094 - mae: 4.6094\n",
      "Epoch 371/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6538 - mae: 4.6538\n",
      "Epoch 372/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.3663 - mae: 4.3663\n",
      "Epoch 373/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7262 - mae: 4.7262\n",
      "Epoch 374/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.4971 - mae: 4.4971\n",
      "Epoch 375/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.4021 - mae: 4.4021\n",
      "Epoch 376/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.4655 - mae: 4.4655\n",
      "Epoch 377/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 256.4392 - mae: 256.4392\n",
      "Epoch 378/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.3727 - mae: 5.3727\n",
      "Epoch 379/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9414 - mae: 4.9414\n",
      "Epoch 380/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8880 - mae: 4.8880\n",
      "Epoch 381/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.0160 - mae: 5.0160\n",
      "Epoch 382/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.2241 - mae: 5.2241\n",
      "Epoch 383/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7837 - mae: 4.7837\n",
      "Epoch 384/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7414 - mae: 4.7414\n",
      "Epoch 385/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9179 - mae: 4.9179\n",
      "Epoch 386/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6950 - mae: 4.6950\n",
      "Epoch 387/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6473 - mae: 4.6473\n",
      "Epoch 388/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.4487 - mae: 4.4487\n",
      "Epoch 389/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5395 - mae: 4.5395\n",
      "Epoch 390/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7027 - mae: 4.7027\n",
      "Epoch 391/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9305 - mae: 4.9305\n",
      "Epoch 392/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.4371 - mae: 4.4371\n",
      "Epoch 393/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8860 - mae: 4.8860\n",
      "Epoch 394/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6104 - mae: 4.6104\n",
      "Epoch 395/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6329 - mae: 4.6329\n",
      "Epoch 396/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.4438 - mae: 4.4438\n",
      "Epoch 397/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5921 - mae: 4.5921\n",
      "Epoch 398/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7414 - mae: 4.7414\n",
      "Epoch 399/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6899 - mae: 4.6899\n",
      "Epoch 400/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.4660 - mae: 4.4660\n",
      "Epoch 401/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6096 - mae: 4.6096\n",
      "Epoch 402/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.3190 - mae: 5.3190\n",
      "Epoch 403/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9415 - mae: 4.9415\n",
      "Epoch 404/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.4341 - mae: 4.4341\n",
      "Epoch 405/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6040 - mae: 4.6040\n",
      "Epoch 406/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8757 - mae: 4.8757\n",
      "Epoch 407/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7103 - mae: 4.7103\n",
      "Epoch 408/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7229 - mae: 4.7229\n",
      "Epoch 409/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8505 - mae: 4.8505\n",
      "Epoch 410/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.2062 - mae: 5.2062\n",
      "Epoch 411/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7495 - mae: 4.7495\n",
      "Epoch 412/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7273 - mae: 4.7273\n",
      "Epoch 413/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5096 - mae: 4.5096\n",
      "Epoch 414/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7943 - mae: 4.7943\n",
      "Epoch 415/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5115 - mae: 4.5115\n",
      "Epoch 416/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9074 - mae: 4.9074\n",
      "Epoch 417/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6691 - mae: 4.6691\n",
      "Epoch 418/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 171.1257 - mae: 171.1257\n",
      "Epoch 419/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.6792 - mae: 5.6792\n",
      "Epoch 420/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.6521 - mae: 5.6521\n",
      "Epoch 421/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9726 - mae: 4.9726\n",
      "Epoch 422/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.4594 - mae: 5.4594\n",
      "Epoch 423/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6034 - mae: 4.6034\n",
      "Epoch 424/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8914 - mae: 4.8914\n",
      "Epoch 425/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8694 - mae: 4.8694\n",
      "Epoch 426/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7197 - mae: 4.7197\n",
      "Epoch 427/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8787 - mae: 4.8787\n",
      "Epoch 428/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9969 - mae: 4.9969\n",
      "Epoch 429/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9127 - mae: 4.9127\n",
      "Epoch 430/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.0196 - mae: 5.0196\n",
      "Epoch 431/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5177 - mae: 4.5177\n",
      "Epoch 432/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7125 - mae: 4.7125\n",
      "Epoch 433/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6982 - mae: 4.6982\n",
      "Epoch 434/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6409 - mae: 4.6409\n",
      "Epoch 435/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.1761 - mae: 5.1761\n",
      "Epoch 436/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5894 - mae: 4.5894\n",
      "Epoch 437/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6514 - mae: 4.6514\n",
      "Epoch 438/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8526 - mae: 4.8526\n",
      "Epoch 439/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7505 - mae: 4.7505\n",
      "Epoch 440/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6114 - mae: 4.6114\n",
      "Epoch 441/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8357 - mae: 4.8357\n",
      "Epoch 442/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7336 - mae: 4.7336\n",
      "Epoch 443/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8146 - mae: 4.8146\n",
      "Epoch 444/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 6.9820 - mae: 6.9820\n",
      "Epoch 445/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5906 - mae: 4.5906\n",
      "Epoch 446/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.4601 - mae: 4.4601\n",
      "Epoch 447/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6865 - mae: 4.6865\n",
      "Epoch 448/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.3905 - mae: 4.3905\n",
      "Epoch 449/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6537 - mae: 4.6537\n",
      "Epoch 450/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9420 - mae: 4.9420\n",
      "Epoch 451/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.4157 - mae: 5.4157\n",
      "Epoch 452/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7938 - mae: 4.7938\n",
      "Epoch 453/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9538 - mae: 4.9538\n",
      "Epoch 454/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5440 - mae: 4.5440\n",
      "Epoch 455/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6782 - mae: 4.6782\n",
      "Epoch 456/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6174 - mae: 4.6174\n",
      "Epoch 457/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5857 - mae: 4.5857\n",
      "Epoch 458/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 65.6303 - mae: 65.6303\n",
      "Epoch 459/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.5570 - mae: 5.5570\n",
      "Epoch 460/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8303 - mae: 4.8303\n",
      "Epoch 461/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9189 - mae: 4.9189\n",
      "Epoch 462/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.0018 - mae: 5.0018\n",
      "Epoch 463/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.8382 - mae: 4.8382\n",
      "Epoch 464/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6040 - mae: 4.6040\n",
      "Epoch 465/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6173 - mae: 4.6173\n",
      "Epoch 466/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6596 - mae: 4.6596\n",
      "Epoch 467/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6497 - mae: 4.6497\n",
      "Epoch 468/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5531 - mae: 4.5531\n",
      "Epoch 469/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5856 - mae: 4.5856\n",
      "Epoch 470/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6261 - mae: 4.6261\n",
      "Epoch 471/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7627 - mae: 4.7627\n",
      "Epoch 472/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.4532 - mae: 4.4532\n",
      "Epoch 473/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.4808 - mae: 4.4808\n",
      "Epoch 474/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9488 - mae: 4.9488\n",
      "Epoch 475/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5104 - mae: 4.5104\n",
      "Epoch 476/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5673 - mae: 4.5673\n",
      "Epoch 477/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9142 - mae: 4.9142\n",
      "Epoch 478/500\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 4.6796 - mae: 4.6796\n",
      "Epoch 479/500\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 4.6406 - mae: 4.6406\n",
      "Epoch 480/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7406 - mae: 4.7406\n",
      "Epoch 481/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6923 - mae: 4.6923\n",
      "Epoch 482/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.4950 - mae: 4.4950\n",
      "Epoch 483/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.8538 - mae: 5.8538\n",
      "Epoch 484/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 285.8126 - mae: 285.8126\n",
      "Epoch 485/500\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 6.9524 - mae: 6.9524\n",
      "Epoch 486/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.1070 - mae: 5.1070\n",
      "Epoch 487/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.0090 - mae: 5.0090\n",
      "Epoch 488/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7390 - mae: 4.7390\n",
      "Epoch 489/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6596 - mae: 4.6596\n",
      "Epoch 490/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.0948 - mae: 5.0948\n",
      "Epoch 491/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6344 - mae: 4.6344\n",
      "Epoch 492/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5329 - mae: 4.5329\n",
      "Epoch 493/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 5.1669 - mae: 5.1669\n",
      "Epoch 494/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9659 - mae: 4.9659\n",
      "Epoch 495/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 0s 1ms/step - loss: 4.4348 - mae: 4.4348\n",
      "Epoch 496/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.5962 - mae: 4.5962\n",
      "Epoch 497/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.7244 - mae: 4.7244\n",
      "Epoch 498/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6414 - mae: 4.6414\n",
      "Epoch 499/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.9674 - mae: 4.9674\n",
      "Epoch 500/500\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 4.6562 - mae: 4.6562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26fcb3354f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9e969fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 932us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[455.40088],\n",
       "       [437.22995],\n",
       "       [432.44232],\n",
       "       ...,\n",
       "       [480.07285],\n",
       "       [434.61005],\n",
       "       [458.74246]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions by letting see more train data epoch = 500\n",
    "y_pred_2_1 = model.predict(X_test)\n",
    "y_pred_2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40497c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 797us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[455.84732],\n",
       "       [437.32993],\n",
       "       [432.47147],\n",
       "       ...,\n",
       "       [480.79495],\n",
       "       [434.62814],\n",
       "       [458.93417]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions by letting see more train data + adding another layer\n",
    "y_pred_2_2 = model.predict(X_test)\n",
    "y_pred_2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e491d3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 780us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[457.6778 ],\n",
       "       [440.13263],\n",
       "       [435.2328 ],\n",
       "       ...,\n",
       "       [481.909  ],\n",
       "       [437.37256],\n",
       "       [461.2503 ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions by letting see more train data + adding another layer + another layer\n",
    "y_pred_2_3 = model.predict(X_test)\n",
    "y_pred_2_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e266002",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_v2_1, mse_v2_1 = evaluation(y_test, y_pred_2_1)\n",
    "mae_v2_2, mse_v2_2 = evaluation(y_test, y_pred_2_2)\n",
    "mae_v2_3, mse_v2_3 = evaluation(y_test, y_pred_2_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "798b5c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model_2_1</td>\n",
       "      <td>3.975710</td>\n",
       "      <td>25.312296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model_2_2</td>\n",
       "      <td>3.980269</td>\n",
       "      <td>25.473391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model_2_3</td>\n",
       "      <td>4.119644</td>\n",
       "      <td>25.897701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model       MAE        MSE\n",
       "0  Model_2_1  3.975710  25.312296\n",
       "1  Model_2_2  3.980269  25.473391\n",
       "2  Model_2_3  4.119644  25.897701"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results = [[\"Model_2_1\", mae_v2_1.numpy(), mse_v2_1.numpy()],\n",
    "                [\"Model_2_2\", mae_v2_2.numpy(), mse_v2_2.numpy()],\n",
    "                [\"Model_2_3\", mae_v2_3.numpy(), mse_v2_3.numpy()]]\n",
    "\n",
    "all_results = pd.DataFrame(model_results, columns=[\"Model\", \"MAE\", \"MSE\"])\n",
    "all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bead0a6",
   "metadata": {},
   "source": [
    "Model_2_1 is performing really well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e6d6b0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1 = tf.squeeze(y_pred_2_1)\n",
    "y_pred2 = tf.squeeze(y_pred_2_2)\n",
    "y_pred3 = tf.squeeze(y_pred_2_3)\n",
    "y_pred1.ndim, y_pred3.ndim, y_pred3.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e1986839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>Model_1</th>\n",
       "      <th>Model_2</th>\n",
       "      <th>Model_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>455.27</td>\n",
       "      <td>456.032318</td>\n",
       "      <td>455.847321</td>\n",
       "      <td>457.677795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>436.31</td>\n",
       "      <td>437.590302</td>\n",
       "      <td>437.329926</td>\n",
       "      <td>440.132629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>440.68</td>\n",
       "      <td>432.658417</td>\n",
       "      <td>432.471466</td>\n",
       "      <td>435.232788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>434.40</td>\n",
       "      <td>437.455597</td>\n",
       "      <td>437.196930</td>\n",
       "      <td>440.015259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>482.06</td>\n",
       "      <td>479.630981</td>\n",
       "      <td>479.348114</td>\n",
       "      <td>480.473083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>430.24</td>\n",
       "      <td>429.472076</td>\n",
       "      <td>429.355682</td>\n",
       "      <td>432.149963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>473.20</td>\n",
       "      <td>475.214996</td>\n",
       "      <td>474.941406</td>\n",
       "      <td>476.177399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>479.53</td>\n",
       "      <td>481.099182</td>\n",
       "      <td>480.794952</td>\n",
       "      <td>481.908997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>435.76</td>\n",
       "      <td>434.863037</td>\n",
       "      <td>434.628143</td>\n",
       "      <td>437.372559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>457.10</td>\n",
       "      <td>459.427124</td>\n",
       "      <td>458.934174</td>\n",
       "      <td>461.250305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1914 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_test     Model_1     Model_2     Model_3\n",
       "0     455.27  456.032318  455.847321  457.677795\n",
       "1     436.31  437.590302  437.329926  440.132629\n",
       "2     440.68  432.658417  432.471466  435.232788\n",
       "3     434.40  437.455597  437.196930  440.015259\n",
       "4     482.06  479.630981  479.348114  480.473083\n",
       "...      ...         ...         ...         ...\n",
       "1909  430.24  429.472076  429.355682  432.149963\n",
       "1910  473.20  475.214996  474.941406  476.177399\n",
       "1911  479.53  481.099182  480.794952  481.908997\n",
       "1912  435.76  434.863037  434.628143  437.372559\n",
       "1913  457.10  459.427124  458.934174  461.250305\n",
       "\n",
       "[1914 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_df = pd.concat([pd.DataFrame({\"y_test\": y_test}),\n",
    "                   pd.DataFrame({\"Model_1\" : y_pred1}),\n",
    "                   pd.DataFrame({\"Model_2\" : y_pred2}),\n",
    "                   pd.DataFrame({\"Model_3\" : y_pred3})], axis = 1)\n",
    "con_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "494fdb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Best_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Saving model_2\n",
    "model.save(\"Best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ec200e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load in the SavedModel format model\n",
    "best_model = tf.keras.models.load_model(\"Best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a246b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (Dense)         (None, 100)               500       \n",
      "                                                                 \n",
      " Input_layer_2 (Dense)       (None, 100)               10100     \n",
      "                                                                 \n",
      " Input_layer_3 (Dense)       (None, 100)               10100     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20801 (81.25 KB)\n",
      "Trainable params: 20801 (81.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "323bd748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (Dense)         (None, 100)               500       \n",
      "                                                                 \n",
      " Input_layer_2 (Dense)       (None, 100)               10100     \n",
      "                                                                 \n",
      " Input_layer_3 (Dense)       (None, 100)               10100     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20801 (81.25 KB)\n",
      "Trainable params: 20801 (81.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
